---
title: 记一次频繁FullGC问题解决
excerpt: 'Spring'
tags: [Spring]
categories: [Spring]
comments: true
date: 2021-11-26 16:30:10
---


今天由于一个同事出差和上海一个病例同坐了一列高铁，我们又开始了全员核酸和流调，不过还好，有了上次的经验，公司安排的很明白，效率比上次高了很多，核酸开始比上次晚，却比上次早结束，十点多就解禁了。

下午五点多，告警群突然一阵急促的告警，显示mq超时，然后是一堆业务接口超时，最后服务都自动重启了。好在探活机制重启了服务，业务影响比较小。

看了一眼大禹（我们的监控平台），Full GC频繁，并且每次GC仅仅释放少量内存，而且停顿时间最长已经到了2-3s，非常恐怖。我们看了一下超时的mq消息，是埋点相关的。我由埋点数据比较大，而且不知为何这里埋点用的是同步消息，联想到可能是用户操作产生的埋点信息产生大量的大对象，直接进入了老年代，而且因为超时的同步消息，这些对象都有引用不能回收，导致老年代被占满，大禹的探活接口超时，重启了服务。

当然以上都是我根据自己的认知的猜测，也没能继续追溯，因为服务重启，pod已经销毁，没能dump当时的内存来分析。

吃完晚饭，做完核酸，组长回来了，于是请大佬帮忙分析一下。大佬只一个`jmap -histo:live ${pid} | grep ${我们的业务标识}`。也就是看看现在存活的业务对象，然后一眼发现权限对象存在超多示例，实例数冠绝全场。然后让我们打开项目，看了下权限相关的代码，发现TMD权限根本就没存在redis……每次客户端来鉴权，都会查数据库，然后生成一个崭新的权限数据对象……

修复后Full GC次数明显减少，并且保持在一个合理的值。
